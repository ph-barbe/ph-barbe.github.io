---
layout: post
title: "AI and ML: are we back to a pre-scientific era?"
image: airship-1670_cropped.png
credit: 
---
If you drop a penny from the height of your waist, it will take slightly less than half a second to hit the floor.

Newton's laws of motion imply that the acceleration of the coin is constant and the distance it travels is proportional to the square of the time it travels. Experiments have shown that the proportionality constant is about 9.8 meters/second squared.

How do did Newton figured that out? Not because it is a law physics, but because scientists patiently experimented.

They not only observed objects falling but also the motion of planets. They studied the data and built models with each one refining the process of the previous one.

After more than 2000 years of research, scientists became confident that the relation between position and time for an object falling was indeed quadratic.

Up to a point. Because if you drop your coin from a much higher altitude than your waist, then friction with air must be accounted for as it slows down the object and limits the maximal speed it can reach. If you drop the coin from an even higher altitude, from space, then the coin may never reach the earth because as it falls the atmosphere it will eat to a point where it will disintegrate, never reaching the ground as a coin. Drop it from even further and the coin may be attracted by a different mass than earth.

We know a lot about falling objects, not because we have a lot of objects that fall but because it is reasonably easy to make objects fall, do some measurement on their falls, observe the data and with some thinking abstract a law of physics. This “law” is a conclusion derived from experiments.

A modern way of figuring out this law would be to use AI or ML. We could take objects, drop them from different heights, measure how long it takes them to reach the ground along with the time of day, temperature, longitude and latitude, humidity, etc. Through the application of an algorithm, a computer would fit a model.

Unfortunately, we would have great doubts about the overall quality of the model that AI/ML generated.

If, in one of our many experiments, we had dropped a sheet of paper or a tree leaf, we’d observe that those objects fall slower than other objects. We would then introduce a new feature, the *material*.

As we’d do a lot of experiments across the planet, we’d record longitude and latitude. Perhaps we would have been smart enough to measure altitude, and noted that in the model there seems to be something going on between altitude, longitude and latitude, depending on which algorithm we choose.

Since different algorithms would have given us different models we would use a model selection procedure. But, a colleague, using the same data and choosing different parameters for their model selection would have come up with a different model than we did.

If both of us were tasked with designing a lunar landing module we would be amused and comforted that despite our models being different, our lunar modules are similar, because our models have similar predictive powers. Unfortunately none of our lunar modules would be able to land: because the moon’s gravity is much less than where we gathered our data to feed into the AI/ML algorithm to generate our models whose predictions would be quite valid on Earth. But an engine designed to slow the descent of a rocket for landing on earth is way too powerful to land on the moon. The rocket would fly off into space instead of landing!

What distinguishes the pre-scientific era (prior to the 18th century) from the scientific era (after the 19th century) is the understanding that there are causes and consequences. Besides being a poet, Goethe was also a scientist who tried to understand lightning and wrote about it. As a keen observer, he recorded anything that he perceived happening when lightening flashed… that the neighbor’s dog barked was as important as the rain falling, or the presence of clouds.

Looking at current trends in Data Science, AI and ML, I sometimes feel that we are going back to a pre-scientific era. That may sound pessimistic, but not if one remembers that the scientific era followed the pre-scientific one. The scientific revolution did not occur because conventional people kept seeing *all* events as possible causes, but because some scientists took the time to study the data, examine the world, and thought deeply about ***why*** things happen, to distinguish between causes, consequences and irrelevance.

The massification of AI and ML, and the ease with which data can be accumulated and algorithms used, has created a massification of scientism.

It is progress, in the sense that many things seem more predictable, as long as their environment remains constant.

But my skeptical scientific-self questions if we became wiser, making predictions with these shiny objects that we now hold in our hands. I wonder how long our models will last in a world of changes. Will they become childhood treasures whose value diminishes as we grow up, becoming so irrelevant that one day we throw them away?

But the reality of the day takes me back to the optimism of the moment, and I go back to building my shiny objects which time will sand, removing some of their shine.